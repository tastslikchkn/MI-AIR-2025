---
marp: true
---

# MI-AIR-2025 Local LLM Series ðŸš€

Welcome! This is a creative, code-friendly slide deck built with Marp and Markdown.

---

## Part 1: DIY Local LLM Bootcamp ðŸ¤–

- What are LLMs? Why run them locally?
- Tools: Ollama, LM Studio
- Installation & configuration
- Inference & resource monitoring
- Practical CLI & RAG chatbot demos

---

## Part 2: Bridging Local LLMs to Apps ðŸ”—

- Integrating LLMs with chatbots, data tools, IDEs
- RESTful APIs & security
- Python, LangChain, analytics
- IDE integration demo

---

## Part 3: Vibe Coding with Local LLMs âœ¨

- Vibe Coding: real-time code suggestions
- VSCode setup & extensions
- Prompt engineering
- Advanced workflows

---

## Live Demo & Q&A ðŸ’¬

- See `.github/assets/demo.gif` for a workflow example
- Join the [Discussions](../../discussions) for Q&A

---

## Thank You! ðŸŽ‰

- Explore the repo for more resources
- All content is accessible via GitHub Markdown
